api_key: 07dd098280c741d1e0f8b19587d8f5ce

# dd_url: https://app.datadoghq.com

## @param proxy - custom object - optional
## @env DD_PROXY_HTTP - string - optional
## @env DD_PROXY_HTTPS - string - optional
## @env DD_PROXY_NO_PROXY - space separated list of strings - optional
## If you need a proxy to connect to the Internet, provide it here (default:
## disabled). Refer to https://docs.datadoghq.com/agent/proxy/ to understand how to use these settings.
## For Logs proxy information, refer to https://docs.datadoghq.com/agent/proxy/#proxy-for-logs
#
proxy:
#   https: http://<USERNAME>:<PASSWORD>@<PROXY_SERVER_FOR_HTTPS>:<PORT>
  http: http://127.0.0.1:3834
#   no_proxy:
#     - <HOSTNAME-1>
#     - <HOSTNAME-2>

## @param skip_ssl_validation - boolean - optional - default: false
## @env DD_SKIP_SSL_VALIDATION - boolean - optional - default: false
## Setting this option to "true" tells the Agent to skip validation of SSL/TLS certificates.
#
# skip_ssl_validation: false

## @param min_tls_version - string - optional - default: "tlsv1.0"
## @env DD_MIN_TLS_VERSION - string - optional - default: "tlsv1.0"
## This option defines the minimum TLS version that will be used when
## submitting data to the Datadog intake specified in "site" or "dd_url".
## This parameter defaults to "tlsv1.2".
## Possible values are: tlsv1.0, tlsv1.1, tlsv1.2, tlsv1.3; values are case-
## insensitive.
#
# min_tls_version: "tlsv1.2"

tags:
  - team:proxy-servers

GUI_port: 10458

##################################
## Log collection Configuration ##
##################################

## @param logs_enabled - boolean - optional - default: false
## @env DD_LOGS_ENABLED - boolean - optional - default: false
## Enable Datadog Agent log collection by setting logs_enabled to true.
#
logs_enabled: true

## @param logs_config - custom object - optional
## Enter specific configurations for your Log collection.
## Uncomment this parameter and the one below to enable them.
## See https://docs.datadoghq.com/agent/logs/
#
logs_config:

  ## @param container_collect_all - boolean - optional - default: false
  ## @env DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL - boolean - optional - default: false
  ## Enable container log collection for all the containers (see ac_exclude to filter out containers)
  #
  # container_collect_all: false

  ## @param logs_dd_url - string - optional
  ## @env DD_LOGS_CONFIG_DD_URL - string - optional
  ## Define the endpoint and port to hit when using a proxy for logs. The logs are forwarded in TCP
  ## therefore the proxy must be able to handle TCP connections.
  #
  logs_dd_url: 127.0.0.1:3838

  ## @param logs_no_ssl - boolean - optional - default: false
  ## @env DD_LOGS_CONFIG_LOGS_NO_SSL - optional - default: false
  ## Disable the SSL encryption. This parameter should only be used when logs are
  ## forwarded locally to a proxy. It is highly recommended to then handle the SSL encryption
  ## on the proxy side.
  #
  # logs_no_ssl: false

  ## @param processing_rules - list of custom objects - optional
  ## @env DD_LOGS_CONFIG_PROCESSING_RULES - list of custom objects - optional
  ## Global processing rules that are applied to all logs. The available rules are
  ## "exclude_at_match", "include_at_match" and "mask_sequences". More information in Datadog documentation:
  ## https://docs.datadoghq.com/agent/logs/advanced_log_collection/#global-processing-rules
  #
  # processing_rules:
  #   - type: <RULE_TYPE>
  #     name: <RULE_NAME>
  #     pattern: <RULE_PATTERN>

  ## @param force_use_http - boolean - optional - default: false
  ## @env DD_LOGS_CONFIG_FORCE_USE_HTTP - boolean - optional - default: false
  ## By default, the Agent sends logs in HTTPS batches to port 443 if HTTPS connectivity can
  ## be established at Agent startup, and falls back to TCP otherwise. Set this parameter to `true` to
  ## always send logs with HTTPS (recommended).
  #
  force_use_http: true

  ## @param force_use_tcp - boolean - optional - default: false
  ## @env DD_LOGS_FORCE_USE_TCP - boolean - optional - default: false
  ## By default, logs are sent through HTTPS if possible, set this parameter
  ## to `true` to always send logs via TCP. If `use_http` is set to `true`, this parameter
  ## is ignored.
  #
  # force_use_tcp: true

  ## @param use_compression - boolean - optional - default: false
  ## @env DD_LOGS_CONFIG_USE_COMPRESSION - boolean - optional - default: false
  ## This parameter is available when sending logs with HTTPS. If enabled, the Agent
  ## compresses logs before sending them.
  #
  # use_compression: true

  ## @param compression_level - integer - optional - default: 6
  ## @env DD_LOGS_CONFIG_COMPRESSION_LEVEL - boolean - optional - default: false
  ## The compression_level parameter accepts values from 0 (no compression)
  ## to 9 (maximum compression but higher resource usage). Only takes effect if
  ## `use_compression` is set to `true`.
  #
  # compression_level: 6

  ## @param batch_wait - integer - optional - default: 5
  ## @env DD_LOGS_CONFIG_BATCH_WAIT - integer - optional - default: 5
  ## The maximum time the Datadog Agent waits to fill each batch of logs before sending.
  #
  # batch_wait: 5

  ## @param open_files_limit - integer - optional - default: 500
  ## @env DD_LOGS_CONFIG_OPEN_FILES_LIMIT - integer - optional - default: 500
  ## The maximum number of files that can be tailed in parallel.
  ## Note: the default for windows and Mac OS is 200. The default for
  ## all other systems is 500.
  #
  # open_files_limit: 500

  ## @param file_wildcard_selection_mode - string - optional - default: `by_name`
  ## @env DD_LOGS_CONFIG_FILE_WILDCARD_SELECTION_MODE - string - optional - default: `by_name`
  ## The strategy used to prioritize wildcard matches if they exceed the open file limit.
  ##
  ## Choices are `by_name` and `by_modification_time`.
  ##
  ## `by_name` means that each log source is considered and the matching files are ordered
  ## in reverse name order. While there are less than `logs_config.open_files_limit` files
  ## being tailed, this process repeats, collecting from each configured source.
  ##
  ## `by_modification_time` takes all log sources and first adds any log sources that
  ## point to a specific file. Next, it finds matches for all wildcard sources.
  ## This resulting list is ordered by which files have been most recently modified
  ## and the top `logs_config.open_files_limit` most recently modified files are
  ## chosen for tailing.
  ##
  ## WARNING: `by_modification_time` is less performant than `by_name` and will trigger
  ## more disk I/O at the configured wildcard log paths.
  #
  # file_wildcard_selection_mode: `by_name`

####################################
## Trace Collection Configuration ##
####################################

## @param apm_config - custom object - optional
## Enter specific configurations for your trace collection.
## Uncomment this parameter and the one below to enable them.
## See https://docs.datadoghq.com/agent/apm/
#
apm_config:

  ## @param enabled - boolean - optional - default: true
  ## @env DD_APM_ENABLED - boolean - optional - default: true
  ## Set to true to enable the APM Agent.
  #
  enabled: true

  ## @param env - string - optional - default: none
  ## @env DD_APM_ENV - string - optional - default: none
  ## The environment tag that Traces should be tagged with.
  ## If not set the value will be inherited, in order, from the top level
  ## "env" config option if set and then from the 'env:' tag if present in the
  ## 'tags' top level config option.
  #
  # env: none

  ## @param receiver_port - integer - optional - default: 8126
  ## @env DD_APM_RECEIVER_PORT - integer - optional - default: 8126
  ## The port that the trace receiver should listen on.
  ## Set to 0 to disable the HTTP receiver.
  #
  # receiver_port: 8126

  ## @param receiver_socket - string - optional
  ## @env DD_APM_RECEIVER_SOCKET - string - optional
  ## Accept traces through Unix Domain Sockets.
  ## It is off by default. When set, it must point to a valid socket file.
  #
  # receiver_socket: <UNIX_SOCKET_PATH>

  ## @param apm_non_local_traffic - boolean - optional - default: false
  ## @env DD_APM_NON_LOCAL_TRAFFIC - boolean - optional - default: false
  ## Set to true so the Trace Agent listens for non local traffic,
  ## i.e if Traces are being sent to this Agent from another host/container
  #
  # apm_non_local_traffic: false

  ## @param apm_dd_url - string - optional
  ## @env DD_APM_DD_URL - string - optional
  ## Define the endpoint and port to hit when using a proxy for APM. The traces are forwarded in TCP
  ## therefore the proxy must be able to handle TCP connections.
  #
  apm_dd_url: 127.0.0.1:3835

  ## @param max_traces_per_second - integer - optional - default: 10
  ## @env DD_APM_MAX_TPS - integer - optional - default: 10
  ## The target traces per second to sample. Sampling rates to apply are adjusted given
  ## the received traffic and communicated to tracers. This configures head base sampling.
  ## As of 7.35.0 sampling cannot be disabled and setting 'max_traces_per_second' to 0 no longer
  ## disables sampling, but instead sends no traces to the intake. To avoid rate limiting, set this
  ## value sufficiently high for your traffic pattern.
  #
  # max_traces_per_second: 10

  ## @param errors_per_second - integer - optional - default: 10
  ## @env DD_APM_ERROR_TPS - integer - optional - default: 10
  ## The target error trace chunks to receive per second. The TPS is spread
  ## to catch all combinations of service, name, resource, http.status, and error.type.
  ## Set to 0 to disable the errors sampler.
  #
  # errors_per_second: 10

  ## @param max_events_per_second - integer - optional - default: 200
  ## @env DD_APM_MAX_EPS - integer - optional - default: 200
  ## Maximum number of APM events per second to sample.
  #
  # max_events_per_second: 200

  ## @param max_memory - integer - optional - default: 500000000
  ## @env DD_APM_MAX_MEMORY - integer - optional - default: 500000000
  ## This value is what the Agent aims to use in terms of memory. If surpassed, the API
  ## rate limits incoming requests to aim and stay below this value.
  ## Note: The Agent process is killed if it uses more than 150% of `max_memory`.
  ## Set the `max_memory` parameter to `0` to disable the memory limitation.
  #
  # max_memory: 500000000

  ## @param max_cpu_percent - integer - optional - default: 50
  ## @env DD_APM_MAX_CPU_PERCENT - integer - optional - default: 50
  ## The CPU percentage that the Agent aims to use. If surpassed, the API rate limits
  ## incoming requests to aim and stay below this value. Examples: 50 = half a core, 200 = two cores.
  ## Set `max_cpu_percent` to `0` to disable rate limiting based on CPU usage.
  #
  # max_cpu_percent: 50

  ## @param obfuscation - object - optional
  ## Defines obfuscation rules for sensitive data. Disabled by default.
  ## See https://docs.datadoghq.com/tracing/setup_overview/configure_data_security/#agent-trace-obfuscation
  #
  # obfuscation:
  #     <OBFUSCATION_CONFIGURATION>

  ## @param filter_tags - object - optional
  ## Defines rules by which to filter traces based on tags.
  ##  * require - list of key or key/value strings - traces must have those tags in order to be sent to Datadog
  ##  * reject - list of key or key/value strings - traces with these tags are dropped by the Agent
  ## Note: Rules take into account the intersection of tags defined.
  #
  # filter_tags:
  #     require: [<LIST_OF_KEY_VALUE_TAGS>]
  #     reject: [<LIST_OF_KEY_VALUE_TAGS>]

  ## @param replace_tags - list of objects - optional
  ## @env DD_APM_REPLACE_TAGS  - list of objects - optional
  ## Defines a set of rules to replace or remove certain resources, tags containing
  ## potentially sensitive information.
  ## Each rules has to contain:
  ##  * name - string - The tag name to replace, for resources use "resource.name".
  ##  * pattern - string - The pattern to match the desired content to replace
  ##  * repl - string - what to inline if the pattern is matched
  ##
  ## See https://docs.datadoghq.com/tracing/setup_overview/configure_data_security/#replace-rules-for-tag-filtering
  ##
  #
  # replace_tags:
  #   - name: "<TAG_NAME>"
  #     pattern: "<REGEX_PATTERN>"
  #     repl: "<PATTERN_TO_INLINE>"

  ## @param ignore_resources - list of strings - optional
  ## @env DD_APM_IGNORE_RESOURCES - comma separated list of strings - optional
  ## An exclusion list of regular expressions can be provided to disable certain traces based on their resource name
  ## all entries must be surrounded by double quotes and separated by commas.
  #
  # ignore_resources: ["(GET|POST) /healthcheck"]

  ## @param log_file - string - optional
  ## @env DD_APM_LOG_FILE - string - optional
  ## The full path to the file where APM-agent logs are written.
  #
  # log_file: <APM_LOG_FILE_PATH>

  ## @param log_throttling - boolean - default: true
  ## @env DD_APM_LOG_THROTTLING - boolean - default: true
  ## Limits the total number of warnings and errors to 10 for every 10 second interval.
  #
  # log_throttling: true

  ## @param connection_limit - integer - default: 2000
  ## @env DD_APM_CONNECTION_LIMIT - integer - default: 2000
  ## The APM connection limit for the Agent.
  ## See https://docs.datadoghq.com/tracing/troubleshooting/agent_rate_limits/#max-connection-limit
  #
  # connection_limit: 2000

  ## @param compute_stats_by_span_kind - bool - default: false
  ## @env DD_APM_COMPUTE_STATS_BY_SPAN_KIND - bool - default: false
  ## Enables an additional stats computation check on spans to see they have an eligible `span.kind` (server, consumer, client, producer).
  ## If enabled, a span with an eligible `span.kind` will have stats computed. If disabled, only top-level and measured spans will have stats computed.
  ## NOTE: For stats computed from OTel traces, only top-level spans are considered when this option is off.
  ## If you are sending OTel traces and want stats on non-top-level spans, this flag will need to be enabled.
  # compute_stats_by_span_kind: false

  ## @param peer_service_aggregation - bool - default: false
  ## @env DD_APM_PEER_SERVICE_AGGREGATION - bool - default: false
  ## Enables `peer.service` aggregation in the agent. If disabled, aggregated trace stats will not include `peer.service` as a dimension.
  ## For the best experience with `peer.service`, it is recommended to also enable `compute_stats_by_span_kind`.
  ## If enabling both causes the Agent to consume too many resources, try disabling `compute_stats_by_span_kind` first.
  ## If the overhead remains high, it will be due to a high cardinality of `peer.service` values from the traces. You may need to check your instrumentation.
  ## NOTE: If you are using an OTel tracer it's best to have both enabled because client/producer spans with a `peer.service` value
  ## may not be marked by the Agent as top-level spans.
  # peer_service_aggregation: false

  ## @param features - list of strings - optional
  ## @env DD_APM_FEATURES - comma separated list of strings - optional
  ## Configure additional beta APM features.
  ## The list of items available under apm_config.features is not guaranteed to persist across versions;
  ## a feature may eventually be promoted to its own configuration option on the agent, or dropped entirely.
  #
  # features: ["error_rare_sample_tracer_drop","table_names","component2name","sql_cache"]

  ## @param profiling - custom object - optional
  ## Enter specific configurations for internal profiling.
  ##
  ## Please note that:
  ##   1. This does *not* enable profiling for user applications.
  ##   2. This only enables internal profiling of the agent go runtime.
  ##   3. To enable profiling for user apps please refer to
  ##      https://docs.datadoghq.com/tracing/profiling/
  ##   4. Enabling this feature will incur in billing charges and other
  ##      unexpected side-effects (ie. agent profiles showing with your
  ##      services).
  ##
  ## Uncomment this parameter and the one below to enable profiling.
  #
  # internal_profiling:
  #
    ## @param enabled - boolean - optional - default: false
    ## @env DD_INTERNAL_PROFILING_ENABLED - boolean - optional - default: false
    ## Enable internal profiling for the trace-agent process.
    #
    # enabled: false

######################################
## Process Collection Configuration ##
######################################

## @param process_config - custom object - optional
## Enter specific configurations for your Process data collection.
## Uncomment this parameter and the one below to enable them.
## See https://docs.datadoghq.com/graphing/infrastructure/process/
#
process_config:

  ## @param process_collection - custom object - optional
  ## Specifies settings for collecting processes.
  process_collection:
    ## @param enabled - boolean - optional - default: false
    ## Enables collection of information about running processes.
    enabled: true

  ## @param container_collection - custom object - optional
  ## Specifies settings for collecting containers.
  # container_collection:
    ## @param enabled - boolean - optional - default: true
    ## Enables collection of information about running containers.
    # enabled: true

  ## Deprecated - use `process_collection.enabled` and `container_collection.enabled` instead
  ## @param enabled - string - optional - default: "false"
  ## @env DD_PROCESS_CONFIG_ENABLED - string - optional - default: "false"
  ##  A string indicating the enabled state of the Process Agent:
  ##    * "false"    : The Agent collects only containers information.
  ##    * "true"     : The Agent collects containers and processes information.
  ##    * "disabled" : The Agent process collection is disabled.
  #
  # enabled: "true"

  ## @param expvar_port - string - optional - default: 6062
  ## @env DD_PROCESS_CONFIG_EXPVAR_PORT - string - optional - default: 6062
  ## Port for the debug endpoints for the process Agent.
  #
  # expvar_port: 6062

  ## @param cmd_port - string - optional - default: 6162
  ## Port for configuring runtime settings for the process Agent.
  #
  # cmd_port: 6162

  ## @param log_file - string - optional
  ## @env DD_PROCESS_CONFIG_LOG_FILE - string - optional
  ## The full path to the file where process Agent logs are written.
  #
  # log_file: <PROCESS_LOG_FILE_PATH>

  ## @param intervals - custom object - optional - default: 10s for normal checks and 2s for others.
  ## @env DD_PROCESS_CONFIG_INTERVALS_CONTAINER - integer - optional - default: 10
  ## @env DD_PROCESS_CONFIG_INTERVALS_CONTAINER_REALTIME - integer - optional - default: 2
  ## @env DD_PROCESS_CONFIG_INTERVALS_PROCESS - integer - optional - default: 10
  ## @env DD_PROCESS_CONFIG_INTERVALS_PROCESS_REALTIME - integer - optional - default: 2
  ## The interval, in seconds, at which the Agent runs each check. If you want consistent
  ## behavior between real-time, set the `container_realtime` and `process_realtime` intervals to 10.
  #
  # intervals:
  #   container: 10
  #   container_realtime: 2
  #   process: 10
  #   process_realtime: 2

  ## @param process_discovery - custom object - optional
  ## Specifies custom settings for the `process_discovery` object.
  # process_discovery:
      ## @param enabled - boolean - optional - default: true
      ## Toggles the `process_discovery` check. If enabled, this check gathers information about running integrations.
      # enabled: true

      ## @param interval - duration - optional - default: 4h - minimum: 10m
      ## An interval in hours that specifies how often the process discovery check should run.
      # interval: 4h


  ## @param blacklist_patterns - list of strings - optional
  ## @env DD_PROCESS_CONFIG_BLACKLIST_PATTERNS - space separated list of strings - optional
  ## A list of regex patterns that exclude processes if matched.
  #
  # blacklist_patterns:
  #   - <REGEX>

  ## @param queue_size - integer - optional - default: 256
  ## @env DD_PROCESS_CONFIG_QUEUE_SIZE - integer - optional - default: 256
  ## The number of check results to buffer in memory when a POST fails.
  #
  # queue_size: 256

  ## @param process_queue_bytes - integer - optional - default: 60000000
  ## @env DD_PROCESS_CONFIG_PROCESS_QUEUE_BYTES - integer - optional - default: 60000000
  ## The amount of data (in bytes) to buffer in memory when a POST fails.
  #
  # process_queue_bytes: 60000000

  ## @param rt_queue_size - integer - optional - default: 5
  ## @env DD_PROCESS_CONFIG_RT_QUEUE_SIZE - integer - optional - default: 5
  ## The number of realtime check results to buffer in memory when a POST fails.
  #
  # rt_queue_size: 5

  ## @param max_per_message - integer - optional - default: 100
  ## @env DD_PROCESS_CONFIG_MAX_PER_MESSAGE - integer - optional - default: 100
  ## The maximum number of processes or containers per message.
  #
  # max_per_message: 100

  ## @param dd_agent_bin - string - optional
  ## @env DD_PROCESS_CONFIG_DD_AGENT_BIN - string - optional
  ## Overrides the path to the Agent bin used for getting the hostname. Defaults are:
  ##   * Windows: <AGENT_DIRECTORY>\embedded\\agent.exe
  ##   * Unix: /opt/datadog-agent/bin/agent/agent
  #
  # dd_agent_bin: <AGENT_BIN_PATH>

  ## @param dd_agent_env - string - optional - default: ""
  ## @env DD_PROCESS_CONFIG_DD_AGENT_ENV - string - optional - default: ""
  ## Overrides of the environment we pass to fetch the hostname.
  #
  # dd_agent_env: ""

  ## @param scrub_args - boolean - optional - default: true
  ## @env DD_PROCESS_CONFIG_SCRUB_ARGS - boolean - optional - default: true
  ## Hide sensitive data on the Live Processes page.
  #
  # scrub_args: true

  ## @param custom_sensitive_words - list of strings - optional
  ## @env DD_PROCESS_CONFIG_CUSTOM_SENSITIVE_WORDS - space separated list of strings - optional
  ## Define your own list of sensitive data to be merged with the default one.
  ## Read more on Datadog documentation:
  ## https://docs.datadoghq.com/graphing/infrastructure/process/#process-arguments-scrubbing
  #
  # custom_sensitive_words:
  #   - 'personal_key'
  #   - '*token'
  #   - 'sql*'
  #   - '*pass*d*'

  ## @param disable_realtime_checks - boolean - optional - default: false
  ## @env DD_PROCESS_CONFIG_DISABLE_REALTIME - boolean - optional - default: false
  ## Disable realtime process and container checks
  #
  # disable_realtime_checks: false

  ## @param profiling - custom object - optional
  ## Enter specific configurations for internal profiling.
  ##
  ## Please note that:
  ##   1. This does *not* enable profiling for user applications.
  ##   2. This only enables internal profiling of the agent go runtime.
  ##   3. To enable profiling for user apps please refer to
  ##      https://docs.datadoghq.com/tracing/profiling/
  ##   4. Enabling this feature will incur in billing charges and other
  ##      unexpected side-effects (ie. agent profiles showing with your
  ##      services).
  ##
  ## Uncomment this parameter and the one below to enable profiling.
  #
  # internal_profiling:
  #
  ## @param enabled - boolean - optional - default: false
  ## @env DD_INTERNAL_PROFILING_ENABLED - boolean - optional - default: false
  ## Enable internal profiling for the Process Agent process.
  #
  # enabled: false

#############################################
## Security Agent Compliance Configuration ##
#############################################

## @param compliance_config - custom object - optional
## Enter specific configuration for continuous compliance checks.
# compliance_config:

  ## @param enabled - boolean - optional - default: false
  ## @env DD_COMPLIANCE_CONFIG_ENABLED - boolean - optional - default: false
  ## Set to true to enable Cloud Security Posture Management (CSPM).
  #
  # enabled: false

  ## @param dir - string - optional - default: /etc/datadog-agent/compliance.d
  ## @env DD_COMPLIANCE_CONFIG_DIR - string - optional - default: /etc/datadog-agent/compliance.d
  ## Directory path for compliance checks configuration containing enabled benchmarks
  #
  # dir: /etc/datadog-agent/compliance.d

  ## @param check_interval - duration - optional - default: 20m
  ## @env DD_COMPLIANCE_CONFIG_CHECK_INTERVAL - duration - optional - default: 20m
  ## Check interval (see  https://golang.org/pkg/time/#ParseDuration for available options)
  # check_interval: 20m

  ## @param check_max_events_per_run - integer - optional - default: 100
  ## @env DD_COMPLIANCE_CONFIG_CHECK_MAX_EVENTS_PER_RUN - integer - optional - default: 100
  ##
  # check_max_events_per_run: 100

##################################
## System Probe Configuration ##
##################################

## @param system_probe_config - custom object - optional
## Enter specific configurations for your System Probe data collection.
## Uncomment this parameter and the one below to enable them.
#
# system_probe_config:
  ## @param log_file - string - optional - default: /var/log/datadog/system-probe.log
  ## @env DD_SYSTEM_PROBE_CONFIG_LOG_FILE - string - optional - default: /var/log/datadog/system-probe.log
  ## The full path to the file where system-probe logs are written.
  #
  # log_file: /var/log/datadog/system-probe.log
  ## @param profiling - custom object - optional
  ## Enter specific configurations for internal profiling.
  ##
  ## Please note that:
  ##   1. This does *not* enable profiling for user applications.
  ##   2. This only enables internal profiling of the agent go runtime.
  ##   3. To enable profiling for user apps please refer to
  ##      https://docs.datadoghq.com/tracing/profiling/
  ##   4. Enabling this feature will incur in billing charges and other
  ##      unexpected side-effects (ie. agent profiles showing with your
  ##      services).
  ##
  ## Uncomment this parameter and the one below to enable profiling.
  #
  # internal_profiling:
  #
    ## @param enabled - boolean - optional - default: false
    ## @env DD_INTERNAL_PROFILING_ENABLED - boolean - optional - default: false
    ## Enable internal profiling for the System Probe process.
    #
    # enabled: false

########################################
## System Probe Network Configuration ##
########################################

# network_config:
  ## @param enabled - boolean - optional - default: false
  ## Set to true to enable the Network Module of the System Probe
  #
  # enabled: false


#############################################################
## System Probe Universal Service monitoring Configuration ##
#############################################################

# service_monitoring_config:
## @param enabled - boolean - optional - default: false
## Set to true to enable the Universal Service Monitoring Module of the System Probe
#
# enabled: false

#############################################
## System Probe Data Streams Configuration ##
#############################################

# data_streams_config:
## @param enabled - boolean - optional - default: false
## Set to true to enable the Data Streams Module of the System Probe
#
# enabled: false

#############################
## DogStatsD Configuration ##
#############################

## @param use_dogstatsd - boolean - optional - default: true
## @env DD_USE_DOGSTATSD - boolean - optional - default: true
## Set this option to false to disable the Agent DogStatsD server.
#
# use_dogstatsd: true

## @param dogstatsd_port - integer - optional - default: 8125
## @env DD_DOGSTATSD_PORT - integer - optional - default: 8125
## Override the Agent DogStatsD port.
## Note: Make sure your client is sending to the same UDP port.
#
# dogstatsd_port: 8125

## @param bind_host - string - optional - default: localhost
## @env DD_BIND_HOST - string - optional - default: localhost
## The host to listen on for Dogstatsd and traces. This is ignored by APM when
## `apm_config.apm_non_local_traffic` is enabled and ignored by DogStatsD when `dogstatsd_non_local_traffic`
## is enabled. The trace-agent uses this host to send metrics to.
## The `localhost` default value is invalid in IPv6 environments where dogstatsd listens on "::1".
## To solve this problem, ensure Dogstatsd is listening on IPv4 by setting this value to "127.0.0.1".
#
# bind_host: localhost

## @param dogstatsd_socket - string - optional - default: ""
## @env DD_DOGSTATSD_SOCKET - string - optional - default: ""
## Listen for Dogstatsd metrics on a Unix Socket (*nix only). Set to a valid filesystem path to enable.
#
# dogstatsd_socket: ""

## @param dogstatsd_origin_detection - boolean - optional - default: false
## @env DD_DOGSTATSD_ORIGIN_DETECTION - boolean - optional - default: false
## When using Unix Socket, DogStatsD can tag metrics with container metadata.
## If running DogStatsD in a container, host PID mode (e.g. with --pid=host) is required.
#
# dogstatsd_origin_detection: false

## @param dogstatsd_origin_detection_client - boolean - optional - default: false
## @env DD_DOGSTATSD_ORIGIN_DETECTION_CLIENT - boolean - optional - default: false
## Whether the Agent should use a client-provided container ID to enrich the metrics, events and service checks with container tags.
## Note: This requires using a client compatible with DogStatsD protocol version 1.2.
#
# dogstatsd_origin_detection_client: false

## @param dogstatsd_buffer_size - integer - optional - default: 8192
## @env DD_DOGSTATSD_BUFFER_SIZE - integer - optional - default: 8192
## The buffer size use to receive statsd packets, in bytes.
#
# dogstatsd_buffer_size: 8192

## @param dogstatsd_non_local_traffic - boolean - optional - default: false
## @env DD_DOGSTATSD_NON_LOCAL_TRAFFIC - boolean - optional - default: false
## Set to true to make DogStatsD listen to non local UDP traffic.
#
# dogstatsd_non_local_traffic: false

## @param dogstatsd_stats_enable - boolean - optional - default: false
## @env DD_DOGSTATSD_STATS_ENABLE - boolean - optional - default: false
## Publish DogStatsD's internal stats as Go expvars.
#
# dogstatsd_stats_enable: false

## @param dogstatsd_queue_size - integer - optional - default: 1024
## @env DD_DOGSTATSD_QUEUE_SIZE - integer - optional - default: 1024
## Configure the internal queue size of the Dogstatsd server.
## Reducing the size of this queue will reduce the maximum memory usage of the
## Dogstatsd server but as a trade-off, it could increase the number of packet drops.
#
# dogstatsd_queue_size: 1024

## @param dogstatsd_stats_buffer - integer - optional - default: 10
## @env DD_DOGSTATSD_STATS_BUFFER - integer - optional - default: 10
## Set how many items should be in the DogStatsD's stats circular buffer.
#
# dogstatsd_stats_buffer: 10

## @param dogstatsd_stats_port - integer - optional - default: 5000
## @env DD_DOGSTATSD_STATS_PORT - integer - optional - default: 5000
## The port for the go_expvar server.
#
# dogstatsd_stats_port: 5000

## @param dogstatsd_so_rcvbuf - integer - optional - default: 0
## @env DD_DOGSTATSD_SO_RCVBUF - integer - optional - default: 0
## The number of bytes allocated to DogStatsD's socket receive buffer (POSIX system only).
## By default, the system sets this value. If you need to increase the size of this buffer
## but keep the OS default value the same, you can set DogStatsD's receive buffer size here.
## The maximum accepted value might change depending on the OS.
#
# dogstatsd_so_rcvbuf: 0

## @param dogstatsd_metrics_stats_enable - boolean - optional - default: false
## @env DD_DOGSTATSD_METRICS_STATS_ENABLE - boolean - optional - default: false
## Set this parameter to true to have DogStatsD collects basic statistics (count/last seen)
## about the metrics it processed. Use the Agent command "dogstatsd-stats" to visualize
## those statistics.
#
# dogstatsd_metrics_stats_enable: false

## @param dogstatsd_tags - list of key:value elements - optional
## @env DD_DOGSTATSD_TAGS - list of key:value elements - optional
## Additional tags to append to all metrics, events and service checks received by
## this DogStatsD server.
#
# dogstatsd_tags:
#   - <TAG_KEY>:<TAG_VALUE>
#
## @param dogstatsd_mapper_profiles - list of custom object - optional
## @env DD_DOGSTATSD_MAPPER_PROFILES - list of custom object - optional
## The profiles will be used to convert parts of metrics names into tags.
## If a profile prefix is matched, other profiles won't be tried even if that profile matching rules doesn't match.
## The profiles and matching rules are processed in the order defined in this configuration.
##
## For each profile, following fields are available:
##    name (required): profile name
##    prefix (required): mapping only applies to metrics with the prefix. If set to `*`, it will match everything.
##    mappings: mapping rules, see below.
## For each mapping, following fields are available:
##    match (required): pattern for matching the incoming metric name e.g. `test.job.duration.*`
##    match_type (optional): pattern type can be `wildcard` (default) or `regex` e.g. `test\.job\.(\w+)\.(.*)`
##    name (required): the metric name the metric should be mapped to e.g. `test.job.duration`
##    tags (optional): list of key:value pair of tag key and tag value
##      The value can use $1, $2, etc, that will be replaced by the corresponding element capture by `match` pattern
##      This alternative syntax can also be used: ${1}, ${2}, etc
#
# dogstatsd_mapper_profiles:
#   - name: <PROFILE_NAME>                        # e.g. "airflow", "consul", "some_database"
#     prefix: <PROFILE_PREFIX>                    # e.g. "airflow.", "consul.", "some_database."
#     mappings:
#       - match: <METRIC_TO_MATCH>                # e.g. `test.job.duration.*` to match `test.job.duration.my_job_name`
#         match_type: <MATCH_TYPE>                # e.g. `wildcard` or `regex`
#         name: <MAPPED_METRIC_NAME>              # e.g. `test.job.duration`
#         tags:
#           <TAG_KEY>: <TAG_VALUE_TO_EXPAND>      # e.g. `job_name: "$1"`, $1 is replaced by value capture by *
#       - match: 'test.worker.*.*.start_time'     # to match `test.worker.<worker_type>.<worker_name>.start_time`
#         name: 'test.worker.start_time'
#         tags:
#           worker_type: '$1'
#           worker_name: '$2'
#       - match: 'test\.task\.duration\.(\w+)\.(.*)'     # no need to escape in yaml context using single quote
#         match_type: regex
#         name: 'test.task'
#         tags:
#           task_type: '$1'
#           task_name: '$2'

## @param dogstatsd_mapper_cache_size - integer - optional - default: 1000
## @env DD_DOGSTATSD_MAPPER_CACHE_SIZE - integer - optional - default: 1000
## Size of the cache (max number of mapping results) used by Dogstatsd mapping feature.
#
# dogstatsd_mapper_cache_size: 1000

## @param dogstatsd_entity_id_precedence - boolean - optional - default: false
## @env DD_DOGSTATSD_ENTITY_ID_PRECEDENCE - boolean - optional - default: false
## Disable enriching Dogstatsd metrics with tags from "origin detection" when Entity-ID is set.
#
# dogstatsd_entity_id_precedence: false


## @param dogstatsd_no_aggregation_pipeline - boolean - optional - default: true
## @env DD_DOGSTATSD_NO_AGGREGATION_PIPELINE - boolean - optional - default: true
## Enable the no-aggregation pipeline in DogStatsD: a pipeline receiving metrics
## with timestamp and forwarding them to the intake without extra processing except
## for tagging.
#
# dogstatsd_no_aggregation_pipeline: true

## @param dogstatsd_no_aggregation_pipeline_batch_size - integer - optional - default: 256
## @env DD_DOGSTATSD_NO_AGGREGATION_PIPELINE_BATCH_SIZE - integer - optional - default: 256
## How many metrics maximum in payloads sent by the no-aggregation pipeline to the intake.
#
# dogstatsd_no_aggregation_pipeline_batch_size: 256

## @param statsd_forward_host - string - optional - default: ""
## @env DD_STATSD_FORWARD_HOST - string - optional - default: ""
## Forward every packet received by the DogStatsD server to another statsd server.
## WARNING: Make sure that forwarded packets are regular statsd packets and not "DogStatsD" packets,
## as your other statsd server might not be able to handle them.
#
# statsd_forward_host: ""

## @param statsd_forward_port - integer - optional - default: 0
## @env DD_STATSD_FORWARD_PORT - integer - optional - default: 0
## Port or the "statsd_forward_host" to forward StatsD packet to.
#
# statsd_forward_port: 0

## @param statsd_metric_namespace - string - optional - default: ""
## @env DD_STATSD_METRIC_NAMESPACE - string - optional - default: ""
## Set a namespace for all StatsD metrics coming from this host.
## Each metric received is prefixed with the namespace before it's sent to Datadog.
#
# statsd_metric_namespace: ""

## @param metadata_providers - list of custom object - optional
## @env DD_METADATA_PROVIDERS - list of custom object - optional
## Metadata providers, add or remove from the list to enable or disable collection.
## Intervals are expressed in seconds. You can also set a provider's interval to 0
## to disable it.
#
# metadata_providers:
#   - name: k8s
#     interval: 60


###########################
## Logging Configuration ##
###########################

## @param log_level - string - optional - default: info
## @env DD_LOG_LEVEL - string - optional - default: info
## Minimum log level of the Datadog Agent.
## Valid log levels are: trace, debug, info, warn, error, critical, and off.
## Note: When using the 'off' log level, quotes are mandatory.
#
# log_level: 'info'

## @param log_file - string - optional
## @env DD_LOG_FILE - string - optional
## Path of the log file for the Datadog Agent.
## See https://docs.datadoghq.com/agent/guide/agent-log-files/
#
# log_file: <AGENT_LOG_FILE_PATH>

## @param log_format_json - boolean - optional - default: false
## @env DD_LOG_FORMAT_JSON - boolean - optional - default: false
## Set to 'true' to output Agent logs in JSON format.
#
# log_format_json: false

## @param log_to_console - boolean - optional - default: true
## @env DD_LOG_TO_CONSOLE - boolean - optional - default: true
## Set to 'false' to disable Agent logging to stdout.
#
# log_to_console: true

## @param disable_file_logging - boolean - optional - default: false
## @env DD_DISABLE_FILE_LOGGING - boolean - optional - default: false
## Set to 'true' to disable logging to the log file.
#
# disable_file_logging: false

## @param log_file_max_size - custom - optional - default: 10MB
## @env DD_LOG_FILE_MAX_SIZE - custom - optional - default: 10MB
## Maximum size of one log file. Use either a size (e.g. 10MB) or
## provide value in bytes: 10485760
#
# log_file_max_size: 10MB

## @param log_file_max_rolls - integer - optional - default: 1
## @env DD_LOG_FILE_MAX_ROLLS - integer - optional - default: 1
## Maximum amount of "old" log files to keep.
## Set to 0 to not limit the number of files to create.
#
# log_file_max_rolls: 1

## @param log_to_syslog - boolean - optional - default: false
## @env DD_LOG_TO_SYSLOG - boolean - optional - default: false
## Set to 'true' to enable logging to syslog.
## Note: Even if this option is set to 'false', the service launcher of your environment
## may redirect the Agent process' stdout/stderr to syslog. In that case, if you wish
## to disable logging to syslog entirely, set 'log_to_console' to 'false' as well.
#
# log_to_syslog: false

## @param syslog_uri - string - optional
## @env DD_SYSLOG_URI - string - optional
## Define a custom remote syslog uri if needed. If 'syslog_uri' is left undefined/empty,
## a local domain socket connection is attempted.
#
# syslog_uri: <SYSLOG_URI>

## @param syslog_rfc - boolean - optional - default: false
## @env DD_SYSLOG_RFC - boolean - optional - default: false
## Set to 'true' to output in an RFC 5424-compliant format for Agent logs.
#
# syslog_rfc: false

## @param syslog_pem - string - optional
## @env DD_SYSLOG_PEM - string - optional
## If TLS enabled, you must specify a path to a PEM certificate here.
#
# syslog_pem: <PEM_CERTIFICATE_PATH>

## @param syslog_key - string - optional
## @env DD_SYSLOG_KEY - string - optional
## If TLS enabled, you must specify a path to a private key here.
#
# syslog_key: <PEM_KEY_PATH>

## @param syslog_tls_verify - boolean - optional - default: true
## @env DD_SYSLOG_TLS_VERIFY - boolean - optional - default: true
## If TLS enabled, you may enforce TLS verification here.
#
# syslog_tls_verify: true

## @param log_format_rfc3339 - boolean - optional - default false
## @env DD_LOG_FORMAT_RFC3339 - boolean - optional - default false
## If enabled the Agent will log using the RFC3339 format for the log time.
#
# log_format_rfc3339: false

## @param log_all_goroutines_when_unhealthy - boolean - optional - default false
## @env DD_LOG_ALL_GOROUTINES_WHEN_UNHEALTHY - boolean - optional - default false
## If enabled, when the health probe of an internal component fails, the stack traces
## of all the goroutines are logged.
#
# log_all_goroutines_when_unhealthy: false
